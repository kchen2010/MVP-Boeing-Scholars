{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOn9C71SADOhAHazuVOQtvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kchen2010/MVP-Boeing-Scholars/blob/main/sam2_seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "v5iSIWtw8kwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaYbJZd8qnjo"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python-headless\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "!pip install supervision\n",
        "!pip install pillow numpy matplotlib\n",
        "!pip install lama-cleaner\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sam2 Checkpoint download"
      ],
      "metadata": {
        "id": "lYuNMYGb8xKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints\n",
        "!wget -P checkpoints https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt"
      ],
      "metadata": {
        "id": "_7BdDXk48tuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Setup Steps"
      ],
      "metadata": {
        "id": "AsB--b_a9Bcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I recommend going to the website downloading than importanting into runtime files"
      ],
      "metadata": {
        "id": "0tvhRRAI48Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O input_video.mp4 \"https://www.kaggle.com/datasets/vivek603/vehicle-detection-sample-and-output-videos/download?resource=download&select=Test+Video.mp4\"\n",
        "video_path = \"/content/input_video.mp4\""
      ],
      "metadata": {
        "id": "Hfc0PRgNBpfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main\n",
        "*   Still Frame by Frame\n",
        "*   Yolo v11 for detection (Can be redundant with Sam2)\n",
        "*   Sam2 Segmentation (has detection?)\n",
        "*   OpenCV Inpainting (definetly change this)\n"
      ],
      "metadata": {
        "id": "IGApvfiH9vpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "import matplotlib.pyplot as plt\n",
        "from sam2.build_sam import build_sam2_video_predictor\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from ultralytics import YOLO # Import YOLO\n",
        "\n",
        "class CarSegmentationInpainter:\n",
        "    def __init__(self, checkpoint_path=\"checkpoints/sam2_hiera_large.pt\",\n",
        "                 model_cfg=\"sam2_hiera_l.yaml\"):\n",
        "        \"\"\"Initialize SAM 2 model for car segmentation\"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Initialize SAM 2 predictor\n",
        "        self.predictor = SAM2ImagePredictor.from_pretrained(\n",
        "            \"facebook/sam2-hiera-large\"\n",
        "        )\n",
        "\n",
        "        self.yolo_model = YOLO('yolov11.pt')\n",
        "\n",
        "    def detect_cars_yolo(self, frame):\n",
        "        \"\"\"\n",
        "        Detect cars using YOLO\n",
        "        Returns list of bounding boxes [x1, y1, x2, y2]\n",
        "        \"\"\"\n",
        "        results = self.yolo_model(frame, classes=[2])  # Class 2 is 'car' in COCO dataset\n",
        "\n",
        "        boxes = []\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                # Ensure bounding box coordinates are integers\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        return boxes\n",
        "\n",
        "\n",
        "    def segment_cars(self, frame, car_boxes):\n",
        "        \"\"\"Use SAM 2 to segment cars from bounding boxes\"\"\"\n",
        "        self.predictor.set_image(frame)\n",
        "\n",
        "        all_masks = []\n",
        "        for box in car_boxes:\n",
        "            # Convert box to SAM format\n",
        "            input_box = np.array(box)\n",
        "\n",
        "            # Predict mask\n",
        "            masks, scores, _ = self.predictor.predict(\n",
        "                point_coords=None,\n",
        "                point_labels=None,\n",
        "                box=input_box[None, :],\n",
        "                multimask_output=False,\n",
        "            )\n",
        "\n",
        "            if len(masks) > 0:\n",
        "                all_masks.append(masks[0])\n",
        "\n",
        "        return all_masks\n",
        "\n",
        "    def inpaint_sliding_window(self, frame, masks, window_size=256, stride=128):\n",
        "        \"\"\"\n",
        "        Simple Inpainting using Sliding Window Approach\n",
        "        Returns inpainted frame and combined mask\n",
        "        \"\"\"\n",
        "        h, w = frame.shape[:2]\n",
        "        result = frame.copy()\n",
        "\n",
        "        # Combine all masks\n",
        "        combined_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "        for mask in masks:\n",
        "            combined_mask = np.logical_or(combined_mask, mask).astype(np.uint8)\n",
        "\n",
        "        combined_mask = (combined_mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Simple inpainting using OpenCV (replace with better model)\n",
        "        result = cv2.inpaint(result, combined_mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "        return result, combined_mask\n",
        "\n",
        "    def process_video(self, video_path, output_path=\"output.avi\", max_frames=None): # Changed output extension to .avi due to weird configs\n",
        "        \"\"\"Process video with car segmentation and inpainting\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if max_frames:\n",
        "            total_frames = min(total_frames, max_frames)\n",
        "\n",
        "        # Video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'DIVX') # Using a common codec for .avi\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width*3, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        print(f\"Processing {total_frames} frames...\")\n",
        "\n",
        "        while cap.isOpened() and (max_frames is None or frame_count < max_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detect cars\n",
        "            car_boxes = self.detect_cars_yolo(frame)\n",
        "\n",
        "            # Segment cars with SAM 2\n",
        "            masks = []\n",
        "            if len(car_boxes) > 0:\n",
        "                masks = self.segment_cars(frame, car_boxes)\n",
        "\n",
        "            # Create visualization\n",
        "            vis_frame = frame.copy()\n",
        "            for mask in masks:\n",
        "                # Overlay mask in red\n",
        "                mask_overlay = np.zeros_like(frame)\n",
        "                mask_overlay[mask > 0] = [0, 0, 255]\n",
        "                vis_frame = cv2.addWeighted(vis_frame, 1, mask_overlay, 0.5, 0)\n",
        "\n",
        "            # Draw boxes\n",
        "            for box in car_boxes:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Inpaint\n",
        "            inpainted, mask_img = self.inpaint_sliding_window(frame, masks)\n",
        "\n",
        "            # Create side-by-side comparison\n",
        "            combined = np.hstack([frame, vis_frame, inpainted])\n",
        "            out.write(combined)\n",
        "\n",
        "            frame_count += 1\n",
        "            if frame_count % 30 == 0:\n",
        "                print(f\"Processed {frame_count}/{total_frames} frames\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f\"Video saved to {output_path}\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    #Gemini\n",
        "    def display_video_in_colab(self, video_path):\n",
        "        \"\"\"Display video in Google Colab\"\"\"\n",
        "        mp4 = open(video_path, 'rb').read()\n",
        "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <video width=800 controls>\n",
        "            <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\"))\n",
        "\n",
        "\n",
        "# USAGE\n",
        "\n",
        "# Initialize the segmentation and inpainting pipeline\n",
        "segmenter = CarSegmentationInpainter()\n",
        "\n",
        "# Process video (limit frames for testing)\n",
        "output_avi_path = segmenter.process_video(\n",
        "    video_path,\n",
        "    output_path=\"segmented_inpainted_output.avi\" # Open CV issue with error proned mp4 files. Output to AVI and convert to mp4\n"
      ],
      "metadata": {
        "id": "PQE_6oQV9ukW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d845f12"
      },
      "source": [
        "# Convert the AVI file to MP4 using ffmpeg\n",
        "output_avi_path = \"/content/segmented_inpainted_output.avi\"\n",
        "output_mp4_path = \"segmented_inpainted_output.mp4\"\n",
        "\n",
        "!ffmpeg -i \"$output_avi_path\" -vcodec libx264 -acodec aac \"$output_mp4_path\"\n",
        "print(f\"Converted {output_avi_path} to {output_mp4_path}\")\n",
        "\n",
        "# Display the converted MP4 video\n",
        "segmenter.display_video_in_colab(output_mp4_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}