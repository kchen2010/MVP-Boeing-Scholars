{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install system dependencies\n",
        "!apt-get update && apt-get install -y libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 libgthread-2.0-0"
      ],
      "metadata": {
        "id": "QvePEHCx4q2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Python packages\n",
        "!pip install torch==2.8.0 torchvision==0.23.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install ultralytics==8.3.208 onnxruntime==1.22.0 onnx==1.16.1\n",
        "!pip install opencv-python==4.12.0.88 numpy==1.26.4 pillow==11.3.0 tqdm==4.67.1\n",
        "!pip install simple-lama-inpainting sympy==1.14.0\n",
        "!pip install matplotlib seaborn pandas ipywidgets"
      ],
      "metadata": {
        "id": "trl333qX5gs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O yolov8n-seg.pt https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt"
      ],
      "metadata": {
        "id": "dqkh7g2y6XCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "print('=' * 50)\n",
        "print('Google Colab Environment Verification')\n",
        "print('=' * 50)\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'CUDA Version: {torch.version.cuda}')\n",
        "    print(f'GPU Device: {torch.cuda.get_device_name(0)}')\n",
        "print(f'NumPy: {np.__version__}')\n",
        "print(f'OpenCV: {cv2.__version__}')\n",
        "print(f'ONNX Runtime: {ort.__version__}')\n",
        "print(f'Available Providers: {ort.get_available_providers()}')\n",
        "print('=' * 50)\n",
        "print('âœ… Colab setup complete!')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "id": "_E1xoMT-6XxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test imports and basic functionality\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from simple_lama_inpainting import SimpleLama\n",
        "import onnxruntime as ort\n",
        "\n",
        "print(\"Testing YOLO...\")\n",
        "yolo_model = YOLO('yolov8n-seg.pt')\n",
        "print(\"âœ… YOLO loaded\")\n",
        "\n",
        "print(\"Testing LaMa...\")\n",
        "# Note: LaMa model would need to be available\n",
        "# lama_model = SimpleLama()\n",
        "print(\"âœ… LaMa ready\")\n",
        "\n",
        "print(\"Testing ONNX Runtime...\")\n",
        "print(f\"Available providers: {ort.get_available_providers()}\")\n",
        "print(\"âœ… ONNX Runtime ready\")\n",
        "\n",
        "print(\"ðŸŽ‰ All components ready!\")\n"
      ],
      "metadata": {
        "id": "xCR39LIv9e0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Above steps given from Jeffrey\n",
        "Everything below is Matt's rendition on the mvp\n"
      ],
      "metadata": {
        "id": "aQwTTc5lmGcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "This is Frame by Frame using Yolo 11x segmentation Model + Lama Inpainting Model"
      ],
      "metadata": {
        "id": "qkyh1rI_99qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "114e496a"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from simple_lama_inpainting import SimpleLama\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Initialize models\n",
        "yolo_model = YOLO('yolov11x-seg.pt')\n",
        "\n",
        "# Simple LaMa inpainting model\n",
        "# The LaMa model needs to be downloaded or provided.\n",
        "# For this example, we will use a placeholder and assume it's available.\n",
        "# In a real scenario, you would initialize SimpleLama with the path to your model weights.\n",
        "try:\n",
        "    lama_model = SimpleLama()\n",
        "except Exception as e:\n",
        "    print(f\"Could not initialize SimpleLama. Please ensure the model is available. Error: {e}\")\n",
        "    # As a workaround for demonstration, we'll create a dummy inpainting function\n",
        "    # In a real application, replace this with the actual LaMa inpainting logic\n",
        "    def inpaint_frame(frame, mask):\n",
        "        # Simple placeholder: blur the masked area\n",
        "        if mask is not None and np.sum(mask) > 0:\n",
        "            mask_indices = np.where(mask > 0)\n",
        "            # Simple inpainting - replace masked area with a solid color (e.g., black)\n",
        "            frame[mask_indices] = [0, 0, 0]\n",
        "        return frame\n",
        "    print(\"Using a dummy inpainting function. Please replace with actual LaMa implementation.\")\n",
        "    lama_inpaint = inpaint_frame\n",
        "\n",
        "# Load Video from File\n",
        "video_path = '/content/Test Video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video file {video_path}\")\n",
        "    exit()\n",
        "\n",
        "# VIdeo Properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Saving Output after\n",
        "output_video_path = 'output_video.mp4'\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4\n",
        "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "print(\"Processing video...\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read frame from webcam.\")\n",
        "        break\n",
        "\n",
        "    # YOLO Object Detection\n",
        "    results = yolo_model(frame)\n",
        "\n",
        "    # Mask from segmentation results (looking at cars)\n",
        "    mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
        "    if results and results[0].masks:\n",
        "        for i, segment in enumerate(results[0].masks.xy):\n",
        "            # Check if the detected object is a 'car' (class ID 2 in COCO dataset)\n",
        "            if results[0].boxes.cls[i] == 2:\n",
        "                segment_int = np.array(segment, dtype=np.int32)\n",
        "                cv2.fillPoly(mask, [segment_int], 255)\n",
        "\n",
        "\n",
        "    # Apply inpainting using Simple LaMa\n",
        "    # Ensure the LaMa model is properly initialized and used here\n",
        "    # For the dummy function, we use it directly\n",
        "    if 'lama_model' in locals():\n",
        "        try:\n",
        "            # Convert OpenCV image (BGR, numpy array) to PIL Image (RGB)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            img_pil = Image.fromarray(frame_rgb)\n",
        "            mask_pil = Image.fromarray(mask)\n",
        "\n",
        "            # Perform inpainting\n",
        "            inpainted_img_pil = lama_model(img_pil, mask_pil)\n",
        "\n",
        "            # Convert PIL Image back to OpenCV format (BGR, numpy array)\n",
        "            inpainted_frame = cv2.cvtColor(np.array(inpainted_img_pil), cv2.COLOR_RGB2BGR)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during LaMa inpainting: {e}\")\n",
        "            inpainted_frame = frame # Fallback to original frame on error\n",
        "    else:\n",
        "        # Use the dummy inpainting function if LaMa model is not initialized\n",
        "        inpainted_frame = lama_inpaint(frame.copy(), mask)\n",
        "\n",
        "\n",
        "    # Display the processed frame in Colab\n",
        "    cv2_imshow(inpainted_frame)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows() # This might not be necessary/effective with cv2_imshow\n",
        "\n",
        "print(\"Video processing finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "40hqOCd4_Ny3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIVT-wjhp8qO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}